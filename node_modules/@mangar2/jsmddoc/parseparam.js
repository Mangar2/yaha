/**
 * @license
 * This software is licensed under the GNU LESSER GENERAL PUBLIC LICENSE Version 3. It is furnished
 * "as is", without any support, and with no warranty, express or implied, as to its usefulness for
 * any purpose.
 *
 * @author Volker Böhm
 * @copyright Copyright (c) 2020 Volker Böhm
 */

'use strict'

const { getText, nextDocToken, isDocEndTag } = require('./tags')
const reportError = require('./reporterror')

/**
 * @private
 * @description
 * Searches a parameter with a dedicated name from a list of parameters
 * @param {string} name name of the parameter we are looking for
 * @param {Object[]} parameterList list of parameter definitions
 * @returns {Object} parameter having the searched name
 */
function _getParameter (name, parameterList) {
    let result
    for (const param of parameterList) {
        if (param.name === name) {
            result = param
            break
        }
    }
    return result
}

/**
 * Adds a parameter recursively in the parameter tree
 * @param {string[]} nameList list of name components
 * @param {Object} paramAttributes parameter attributes like type and attributes
 * @param {Object[]} parameterList current list of parameters
 */
function _addParameterRec (nameList, paramAttributes, parameterList) {
    const name = nameList.shift()
    let parameter = _getParameter(name, parameterList)
    if (parameter === undefined) {
        parameter = { name }
        parameterList.push(parameter)
    }
    if (nameList.length > 0) {
        if (parameter.param === undefined) {
            parameter.param = []
        }
        parameter.param = _addParameterRec(nameList, paramAttributes, parameter.param)
    } else {
        for (const attribute in paramAttributes) {
            parameter[attribute] = paramAttributes[attribute]
        }
    }
    return parameterList
}

/**
 * @private
 * @description
 * Extracts the type from a parameter description
 * @param {Tokenizer} tokenizer provides token
 * @returns {Object} with property types
 */
function _parseType (tokenizer) {
    const result = { types: '' }
    if (tokenizer.token === '{') {
        let spacer = ''
        nextDocToken(tokenizer)
        while (tokenizer.token !== '}' && tokenizer.token !== '') {
            if (tokenizer.token !== '|') {
                result.types += spacer + tokenizer.token
            }
            spacer = ', '
            nextDocToken(tokenizer)
        }
        // skip '}'
        tokenizer.nextToken()
    }
    return result
}

/**
 * @private
 * @description
 * parses a default value
 * @param {Tokenizer} tokenizer provides token
 * @returns {string}
 */
function _parseDefault (tokenizer) {
    let defaultValue = ''
    let spacer = ''
    if (tokenizer.token === '=') {
        nextDocToken(tokenizer)
        while (tokenizer.token !== ']' && tokenizer.token !== '' && !isDocEndTag(tokenizer.token)) {
            defaultValue += spacer + tokenizer.token
            spacer = ' '
            nextDocToken(tokenizer)
        }
    }
    return defaultValue
}

/**
 * Parses the attributes of a parameter
 * @param {Tokenizer} tokenizer provides tokens
 * @returns {string}
 */
function _parseAttribute (tokenizer) {
    let attributes = ''
    if (tokenizer.token === '[') {
        attributes = '<optional>'
        nextDocToken(tokenizer)
    }
    return attributes
}

/**
 * @private
 * @description
 * Extracts the name from the parameter line
 * @param {Tokenizer} tokenizer provides token
 * @returns {string[]} array of name chunks
 */
function _parseName (tokenizer, curInfo) {
    const result = []
    const breakToken = ['=', ']', '']
    while (!breakToken.includes(tokenizer.token) && !isDocEndTag(tokenizer.token)) {
        result.push(tokenizer.token)
        nextDocToken(tokenizer)
        if (tokenizer.token !== '.') {
            break
        }
        nextDocToken(tokenizer)
    }
    return result
}

/**
 * @private
 * @description
 * Parses the documentation
 * @param {Tokenizer} tokenizer provides token
 * @retunrs {string}
 */
function _parseDescription (tokenizer) {
    const documentation = getText(tokenizer)
    return documentation
}

/**
 * @description
 * Parses a 'param' tag
 * @param {Tokenizer} tokenizer provides token
 * @param {Object[]} paramList current List of parameter
 * @returns {Object[]} list of parameter including new parameter
 */
function parseParamLine (tokenizer, paramList) {
    const paramAttributes = _parseType(tokenizer)
    paramAttributes.attributes = _parseAttribute(tokenizer)
    const nameList = _parseName(tokenizer)
    paramAttributes.default = _parseDefault(tokenizer)
    if (tokenizer.token === ']') {
        nextDocToken(tokenizer)
    } else if (paramAttributes.attributes === '<optional>') {
        reportError(tokenizer, '] expected')
    }
    paramAttributes.description = _parseDescription(tokenizer)
    paramList = _addParameterRec(nameList, paramAttributes, paramList)
    return paramList
}

/**
 * @description
 * Parses a 'return' tag
 * @param {Tokenizer} tokenizer provides token
 * @returns {Object[]} type and documentation
 */
function parseReturns (tokenizer) {
    const returns = _parseType(tokenizer)
    returns.description = _parseDescription(tokenizer)
    return returns
}

/**
 * @description
 * Parses a 'throw' tag
 * @param {Tokenizer} tokenizer provides token
 * @returns {Object[]} type and documentation
 */
function parseThrows (tokenizer) {
    const throws = _parseType(tokenizer)
    throws.description = _parseDescription(tokenizer)
    return throws
}

module.exports = { parseThrows, parseReturns, parseParamLine }
